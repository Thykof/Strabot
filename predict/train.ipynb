{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en_US.UTF-8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree, svm, linear_model, neural_network, gaussian_process\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit, GridSearchCV, ParameterGrid, cross_validate\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN = 'Open*'\n",
    "HIGH = 'High'\n",
    "LOW = 'Low'\n",
    "CLOSE = 'Close**'\n",
    "VOLUME = 'Volume'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscale(value):\n",
    "    return value * np.std(df_num[CLOSE]) + np.mean(df_num[OPEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset\n",
    "df = pd.read_csv(\"bitcoin-price-all-2.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric\n",
    "def raw_data_to_numeric(raw_data):\n",
    "    data = raw_data.replace('â€¯', '')\n",
    "    data = data.replace(',', '.')\n",
    "    if data == '0':\n",
    "        return np.nan\n",
    "    return float(data)\n",
    "df_num = df[['Open*', 'High', 'Low', 'Close**', 'Volume', 'Market Cap']]\n",
    "df_num = df_num.applymap(raw_data_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN by first known data (for `Volume`)\n",
    "df_num = df_num.fillna(46862700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dates\n",
    "dates = df['Date'].apply(lambda x: datetime.datetime.strptime(x, '%b %d, %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_num = dates.map(datetime.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dated = df_num.copy()\n",
    "df_dated.insert(0, 'Date', dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dated.sort_values(by=['Date'], ascending=True)\n",
    "df_num = df_dated.copy()[['Open*', 'High', 'Low', 'Close**', 'Volume', 'Market Cap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Open*      High       Low   Close**    Volume  Market Cap\n",
      "0     1.434426  1.389760  1.472135  1.413960  2.260594    1.535942\n",
      "1     1.402501  1.379486  1.462052  1.432540  2.422154    1.555256\n",
      "2     1.512686  1.464117  1.480165  1.402411  2.538837    1.523675\n",
      "3     1.505648  1.467654  1.568848  1.510694  2.084588    1.636705\n",
      "4     1.478571  1.450206  1.539506  1.503790  2.282077    1.629392\n",
      "...        ...       ...       ...       ...       ...         ...\n",
      "2580 -0.841637 -0.838682 -0.853942 -0.844468 -0.539968   -0.834211\n",
      "2581 -0.839018 -0.834300 -0.850409 -0.842539 -0.539968   -0.832999\n",
      "2582 -0.833169 -0.830715 -0.846271 -0.839495 -0.539968   -0.831083\n",
      "2583 -0.831877 -0.828950 -0.839214 -0.833805 -0.539968   -0.827501\n",
      "2584 -0.834348 -0.828809 -0.839227 -0.832373 -0.539968   -0.826606\n",
      "\n",
      "[2585 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scale data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "df_norm = pd.DataFrame(scaler.fit_transform(df_num.values), columns=df_num.columns, index=df_num.index)\n",
    "print(df_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames:\n",
    "df_num: numeric variables\n",
    "\n",
    "df_norm: normalized numeric variables\n",
    "\n",
    "dates: dates as datetime object\n",
    "\n",
    "dates_num: dates as numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_, delta, model):\n",
    "    scores = list()\n",
    "    X = df_[['Open*', 'High', 'Low', 'Close**', 'Volume', 'Market Cap']].iloc[:-delta,:]\n",
    "    y = df_[['Close**']].iloc[delta:]\n",
    "    \n",
    "    tscv = TimeSeriesSplit()\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel())\n",
    "    cross = cross_val_score(model, X_test, y_test, cv=10, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    return -np.median(cross), np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287.7231887636583, 0.8448841771088416)\n"
     ]
    }
   ],
   "source": [
    "print(train(df_num, delta, linear_model.LinearRegression(fit_intercept=False, copy_X=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.06916778129557798, 0.6251079920240306)\n"
     ]
    }
   ],
   "source": [
    "print(train(df_norm, delta, neural_network.MLPRegressor(hidden_layer_sizes=(125),\n",
    "                                                        activation='identity',\n",
    "                                                        solver=\"lbfgs\",\n",
    "                                                        alpha=0.005\n",
    "                                                       )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2727.1597655594014, -509.8021970698036)\n",
      "(1.0689150241688029e+30, -1.52523781467793e+55)\n",
      "(3391.2030877403845, -6.054051503201183)\n",
      "(390.6813365384615, 0.013005122990977114)\n"
     ]
    }
   ],
   "source": [
    "print(train(df_num, delta, svm.SVR()))\n",
    "print(train(df_num, delta, linear_model.SGDRegressor()))\n",
    "print(train(df_num, delta, gaussian_process.GaussianProcessRegressor()))\n",
    "print(train(df_num, delta, tree.DecisionTreeRegressor()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "delta = 1\n",
    "\n",
    "X = df_norm[['Open*', 'High', 'Low', 'Close**', 'Volume']].iloc[:-delta,:]\n",
    "y = df_norm['Close**'].iloc[delta:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with the found parameters:\n",
    "\n",
    "model = neural_network.MLPRegressor(hidden_layer_sizes=(100,),\n",
    "                                    activation='relu',\n",
    "                                    solver='lbfgs',\n",
    "                                    alpha=1\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(alpha=1, solver='lbfgs')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-53.79065557093578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-57.21180575, -54.10828577, -26.86363654, -67.44475763,\n",
       "       -63.32479217])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def absolute_error_score(y_true, y_pred):\n",
    "    diff = np.abs(unscale(y_true) - unscale(y_pred)) * -1\n",
    "    return np.average(diff, axis=0)\n",
    "\n",
    "def absolute_error(estimator, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    return absolute_error_score(y_test, y_pred)\n",
    "    \n",
    "cross = cross_val_score(model, X, y, scoring=absolute_error)\n",
    "print(np.mean(cross))\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.4499903672345726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.18303691, -4.4426484 , -1.52245844, -2.06164956, -2.04015852])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def percentage_error_score(y_true, y_pred):\n",
    "    percentage = (np.abs(y_pred - y_true)) / np.abs(y_true) * 100\n",
    "    return -np.average(percentage, axis=0)\n",
    "\n",
    "def percentage_error(estimator, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    return percentage_error_score(y_test, y_pred)\n",
    "cross = cross_val_score(model, X, y, scoring=percentage_error)\n",
    "print(np.mean(cross))\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48982707215265364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.43846154, 0.42307692, 0.67692308, 0.52307692, 0.3875969 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aon(x_close, y_pred, y_true):\n",
    "    # all-or-none principle\n",
    "    return not ((y_pred <= x_close) != (y_true < x_close))\n",
    "        \n",
    "def aon_scorer(estimator, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test).reshape(X_test.shape[0], 1)\n",
    "    X_test_close = pd.DataFrame(X_test[CLOSE])\n",
    "    X_test_close.insert(1, 'y_test', y_test)\n",
    "    X_test_close.insert(1, 'y_pred', y_pred)\n",
    "    aon_series = X_test_close.apply(lambda val: aon(val[CLOSE], val['y_pred'], val['y_test']), axis=1)\n",
    "    return np.mean(aon_series)\n",
    "\"\"\"\n",
    "print(aon(50, 52, 51))\n",
    "print(aon(50, 52, 50))\n",
    "print(aon(50, 50, 50))\n",
    "print(aon(50, 52, 49))\n",
    "print(aon(50, 48, 48))\n",
    "print(aon(50, 48, 51))\n",
    "print(aon(50, 48, 50))\n",
    "\"\"\"\n",
    "cross = cross_val_score(model, X, y, scoring=aon_scorer)\n",
    "print(np.mean(cross))\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-175.72552558084007 79.4429590545589\n",
      "-9.738719682989693 7.608497045500248\n",
      "0.6362075134168157 0.06026372448133699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.34793997, 1.33097339, 2.05436063, 1.51144767, 2.26935697]),\n",
       " 'score_time': array([2.83061409, 2.95782328, 2.46833372, 2.33432412, 2.56323004]),\n",
       " 'test_percentage_error': array([ -5.61611668, -12.5980119 , -23.22306198,  -1.65710827,\n",
       "         -5.59929959]),\n",
       " 'test_absolute_error': array([-163.87517829, -228.05930137, -287.42913598,  -51.57724613,\n",
       "        -147.68676613]),\n",
       " 'test_aon_scorer': array([0.63846154, 0.61538462, 0.68461538, 0.70769231, 0.53488372])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(neural_network.MLPRegressor(hidden_layer_sizes=(100,),\n",
    "                                    activation='tanh',\n",
    "                                    solver='adam',\n",
    "                                    alpha=10\n",
    "                                   ), X, y,\n",
    "                        scoring={\n",
    "                            'percentage_error': percentage_error,\n",
    "                            'absolute_error': absolute_error,\n",
    "                            'aon_scorer': aon_scorer\n",
    "                        })\n",
    "\n",
    "print(np.mean(scores['test_absolute_error']), np.std(scores['test_absolute_error']))\n",
    "print(np.mean(scores['test_percentage_error']), np.std(scores['test_percentage_error']))\n",
    "print(np.mean(scores['test_aon_scorer']), np.std(scores['test_aon_scorer']))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-254.41512980919043 109.96155443086954\n",
      "-14.551338413066498 8.62416807762261\n",
      "0.4942277877161598 0.13067299780435163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.34835124, 0.92362332, 1.04641485, 1.16161299, 1.11511803]),\n",
       " 'score_time': array([1.57846379, 1.71861053, 0.56192613, 0.48001337, 0.32627606]),\n",
       " 'test_percentage_error': array([-21.75833859, -15.7835259 , -25.35147205,  -2.04172889,\n",
       "         -7.82162663]),\n",
       " 'test_absolute_error': array([-286.74074405, -231.13699358, -392.24682489,  -60.37998284,\n",
       "        -301.57110369]),\n",
       " 'test_aon_scorer': array([0.55384615, 0.62307692, 0.48461538, 0.56153846, 0.24806202])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(neural_network.MLPRegressor(hidden_layer_sizes=(100,),\n",
    "                                    activation='logistic',\n",
    "                                    solver='adam',\n",
    "                                    alpha=1\n",
    "                                   ), X, y,\n",
    "                        scoring={\n",
    "                            'percentage_error': percentage_error,\n",
    "                            'absolute_error': absolute_error,\n",
    "                            'aon_scorer': aon_scorer\n",
    "                        })\n",
    "\n",
    "print(np.mean(scores['test_absolute_error']), np.std(scores['test_absolute_error']))\n",
    "print(np.mean(scores['test_percentage_error']), np.std(scores['test_percentage_error']))\n",
    "print(np.mean(scores['test_aon_scorer']), np.std(scores['test_aon_scorer']))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'logistic', 'alpha': 1.0}\n",
      "0.6728395061728395\n"
     ]
    }
   ],
   "source": [
    "#############################################\"\" Search the best parameters:\n",
    "model = neural_network.MLPRegressor()\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    {\n",
    "        'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'alpha': 10.0**np.arange(-3,1),\n",
    "        #'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        #'hidden_layer_sizes': [(100,), (10, 10, 10), (125, 125)]\n",
    "    },\n",
    "    scoring=aon_scorer\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)\n",
    "print(gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "0.8580246913580247\n"
     ]
    }
   ],
   "source": [
    "#############################################\"\" Search the best parameters:\n",
    "model = neural_network.MLPRegressor(activation='logistic',alpha=1)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    {\n",
    "        'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'hidden_layer_sizes': [(100,), (10, 10, 10), (125, 125)]\n",
    "    },\n",
    "    scoring=aon_scorer\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)\n",
    "print(gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 10.0, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "0.7407407407407407\n"
     ]
    }
   ],
   "source": [
    "#############################################\"\" Search the best parameters:\n",
    "model = neural_network.MLPRegressor()\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    {\n",
    "        'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'alpha': 10.0**np.arange(-3,2),\n",
    "        'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'hidden_layer_sizes': [(100,), (10, 10, 10), (125, 125)]\n",
    "    },\n",
    "    scoring=aon_scorer\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)\n",
    "print(gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use TimeSeriesSplit, with sgd solver\n",
    "\n",
    "delta = 2\n",
    "\n",
    "X = df_norm[['Open*', 'High', 'Low', 'Close**', 'Volume']].iloc[:-delta,:]\n",
    "y = df_norm[['Close**']].iloc[delta:]\n",
    "\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X, y.values.ravel(),\n",
    "                                                        shuffle=False,\n",
    "                                                        test_size=0.15\n",
    "                                                       )\n",
    "\n",
    "model = neural_network.MLPRegressor(hidden_layer_sizes=(100,),\n",
    "                                    activation='relu',\n",
    "                                    solver='sgd',\n",
    "                                    alpha=1\n",
    "                                   )\n",
    "scores = list()\n",
    "tscv = TimeSeriesSplit(n_splits=100)\n",
    "for train_index, test_index in tscv.split(X_train0):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model.partial_fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test).reshape(X_test.shape[0], 1)\n",
    "    \n",
    "    diff = np.abs(unscale(y_test) - unscale(y_pred)) * -1\n",
    "    percentage = (np.abs(y_pred - y_test)) / np.abs(y_test) * 100\n",
    "    \n",
    "    scores.append((-np.average(percentage, axis=0), np.average(diff, axis=0)))\n",
    "    \n",
    "    if np.average(percentage, axis=0) < 3:\n",
    "        break\n",
    "\n",
    "y_pred = model.predict(X_test0)\n",
    "print(percentage_error_score(y_pred, y_test0))\n",
    "print(absolute_error_score(y_pred, y_test0))\n",
    "print(scores[-1])\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
